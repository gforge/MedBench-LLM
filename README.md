# MedBench-LLM-Summaries

## Overview

Welcome to the MedBench-LLM-Summaries repository. This repository contains Python code for generating summaries of Electronic Health Records (EHRs) using Large Language Models (LLMs) as part of the MedBench research study. The study aims to evaluate and improve the performance of LLMs in medical documentation tasks.

## Objectives

- **Summary Generation**: Utilize LLMs to generate accurate and comprehensive summaries of fictional EHRs.
- **Benchmarking**: Establish benchmarks to assess the quality and accuracy of LLM-generated summaries.
- **Evaluation**: Implement methods to quantitatively and qualitatively evaluate the generated summaries.

## Methods

- **Data Input**: Process core medical notes and related lab and medication data to prepare inputs for LLMs.
- **Model Usage**: Apply advanced LLMs to generate summaries based on the processed EHR data.
- **Evaluation Metrics**: Use various metrics to evaluate the completeness, accuracy, and quality of the generated summaries.

## Usage

1. **Setup**: Install the required dependencies using `pip install -r requirements.txt`.
2. **Data Preparation**: Prepare the EHR data in the specified format.
3. **Run Summarization**: Use the provided scripts to generate summaries from the EHR data.
4. **Evaluation**: Use the evaluation scripts to assess the quality of the generated summaries.

## Contributing

We welcome contributions from the community. Please refer to our contribution guidelines for more information.

## License

This project is licensed under the MIT License. See the LICENSE file for details.
